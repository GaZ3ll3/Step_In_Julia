{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:a6c89c42204f83043c09072f467a61fa91ee78232d49de48e88fb333966f0d5b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Machine Representation of Numbers ##\n",
      "\n",
      "``Julia`` supports multiple float-point types, including ``Float16`` (half), ``Float32`` (single) and  ``Float64`` (double). Half-precision floating-point numbers are only for storage format, when ``Float16`` type is involved in computation, it will be automatically promoted into ``Float32``. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@printf(\"size of Float64 1.0 is %d.\\n\", sizeof(1.0))\n",
      "@printf(\"size of Float32 1.0 is %d.\\n\", sizeof(float32(1.0)))\n",
      "@printf(\"size of Float16 1.0 is %d.\\n\", sizeof(float16(1.0)))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of Float64 1.0 is 8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\n",
        "size of Float32 1.0 is 4.\n",
        "size of Float16 1.0 is 2.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "``NaN`` and ``Inf`` (as well as ``-Inf``) are special floating-points(IEC559), and can be cast into all floating-point types also be used in arithmetic operations.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@printf(\"Inf * Inf + Inf = %d\\n\", Inf * Inf + Inf) \n",
      "@printf(\"Inf + (-Inf)    = %d\\n\", Inf + (-Inf))\n",
      "@printf(\"Inf * Inf + Inf = %lf\\n\", Inf * Inf + Inf) \n",
      "@printf(\"Inf + (-Inf)    = %lf\\n\", Inf + (-Inf))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Inf * Inf + Inf = Inf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inf + (-Inf)    = NaN\n",
        "Inf * Inf + Inf = Inf\n",
        "Inf + (-Inf)    = NaN\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Epsilon function ``eps`` gives machine accuracy. For single and double accuracy, epsilon will be ``float32(2.0^-23)`` and ``2.0^-53`` relatively. Notice ``eps`` also can be used on ``Float16``, the result will be also a half precision number.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@printf(\"%4.52lf\\n\", eps(Float16))\n",
      "@printf(\"%4.52lf\\n\" ,eps(Float32))\n",
      "@printf(\"%4.52lf\\n\", eps(Float64))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0009765625000000000000000000000000000000000000000000\n",
        "0.0000001192092895507812500000000000000000000000000000\n",
        "0.0000000000000002220446049250313080847263336181640625\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The default rounding mode is ``RoundNearest``, to change the mode, we can use ``with_rounding``. In the following example, ``1.2000000000000001`` cannot be represented, thus ``Julia`` rounds it to the nearest representable floating-point number."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# unable to represent, use default rounding\n",
      "@printf(\"%4.16lf\\n\", 1.2000000000000001)\n",
      "\n",
      "# rounding up\n",
      "with_rounding(Float64, RoundUp) do \n",
      "    @printf(\"%4.16lf\\n\", 1.1 + 0.1)\n",
      "end\n",
      "\n",
      "# rounding down\n",
      "with_rounding(Float64, RoundDown) do \n",
      "    @printf(\"%4.16lf\\n\", 1.1 + 0.1)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2000000000000002\n",
        "1.2000000000000002\n",
        "1.2000000000000000\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For understanding of machine numbers, we take a look at IEEE standard for Single Precision(``Float32``), it consists of one bit of sign, and 8 bits of exponent bitstring, 23 bits of numerical value. Single Precision is ranged from ``-Inf32`` to ``Inf32``. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "- typemax(Float32) == typemin(Float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "true"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``Julia`` provides bits representation of a floating-point number by using ``bits``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Float32 type 1.000001 is first rounded to 1.0000009536743164\n",
      "@printf(\"1.000001f0 is rounded to %4.16lf\\n\", 1.000001f0)\n",
      "\n",
      "# And then its bit representation as 0 01111111 00000000000000000001000\n",
      "@printf(\"its bits reprenstation is %s\\n\", bits(1.000001f0))\n",
      "\n",
      "# The representation means it is positive, exponent as 127(convert to base 10).\n",
      "# And numerical value part as 1 + 2^(-20). \n",
      "# Thus the answer will be (1 + 2^(-20))*2^(127 - 127)\n",
      "@printf(\"Convert to Float32 %4.16lf\\n\", float32(1 + 2.0^(-20)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.000001f0 is rounded to 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".0000009536743164\n",
        "its bits reprenstation is 00111111100000000000000000001000\n",
        "Convert to Float32 1.0000009536743164\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So according to the IEEE standard, the ``Inf32`` is defined as ``0 11111111 00000000000000000000000``, if any of the last 23 bits is nonzero, then it is an ``NaN``, ``Julia`` sets its system ``NaN`` as ``0 11111111 10000000000000000000000``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# bits of Inf32\n",
      "@printf(\"%s\\n\", bits(Inf32))\n",
      "# bits of NaN32\n",
      "@printf(\"%s\\n\", bits(NaN32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "01111111100000000000000000000000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "01111111110000000000000000000000\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fixed Precision Arithmetic ##\n",
      "\n",
      "We are not going to talk about arbitrary-precision arithmetic here, there are many multiple-precision libraries nowadays. \n",
      "\n",
      "### Summation over array ###\n",
      "\n",
      "For simple loop like following would be a bad idea. We shall talk about the algorithm's accuracy as well as cost and stablity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# simple loop of summation over array(double precision)\n",
      "function simple_sum(arr::AbstractArray, first::Int, last::Int)\n",
      "    b = arr[first];\n",
      "    for i = first + 1 : last\n",
      "        @inbounds b += arr[i]\n",
      "    end\n",
      "    return b\n",
      "end\n",
      "\n",
      "function pair_sum(arr::AbstractArray, first::Int, last::Int)\n",
      "    if first + 1024 >= last\n",
      "        return simple_sum(arr, first, last)\n",
      "    end\n",
      "    mid = (last + first) >>> 1;\n",
      "    return pair_sum(arr, first, mid) + pair_sum(arr, mid + 1, last)\n",
      "end\n",
      "\n",
      "function kahan_sum(arr::AbstractArray)\n",
      "    # preallocate memory\n",
      "    n = length(arr)\n",
      "    arr_i = 0.\n",
      "    if (n == 0)\n",
      "        return 0\n",
      "    end\n",
      "    @inbounds s = arr[1]\n",
      "    c = 0.\n",
      "    for i =  2:n\n",
      "        @inbounds arr_i = arr[i]\n",
      "        t = s + arr_i\n",
      "        if abs(s) >= abs(arr_i)\n",
      "            c += ((s-t) + arr_i)\n",
      "        else\n",
      "            c += ((arr_i-t) + s)\n",
      "        end\n",
      "        s = t\n",
      "    end\n",
      "    return s + c\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "kahan_sum (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the worst case of above routine ``simple_sum``, the accumulative error would grow as O(``eps`` n), where ``eps`` is the machine accuracy. On the other hand, the cost of computing is fine, O(n). However, we have other algorithms of summation, such as pairwise summation and Kahan summation. For pairwise summation, the algorithm is simply ``divide and conquer``, however, this reduces the growth of error to O(``eps`` log n), and for Kahan summation, it reduces the error to machine accuracy level as O(``eps``), however, this makes it slower than other methods.\n",
      "\n",
      "For the cost of each routine, Kahan costs most, the others are the same as O(n), but pairwise(cascade) summation can be parallelized. \n",
      "\n",
      "For the accuracy of each routine, we have to look deeper into this. For Kahan's method, since there is always compensation, we can always expect very accurate answer at each step in recursive summation, if performance is not our goal. However, for the simple summation method, the ordering of input array might play a great role in controlling the error.\n",
      "\n",
      "First, we have to think about why summation of harmonic series **converges** on our fix-precision computer(maybe after a long time). When we are adding two numbers ``a + b``, if ``|a|`` is much larger than ``|b|``, then ``b`` probably could not contribute to the sum. Just like following case, ``10^(-15)`` is too small for ``log(10^15)``. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log(10^15) + 0.000000000000001 - log(10^15) == 0.000000000000001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "false"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore, the ordering here really matters. If all numbers of the array ``A`` are postive, then ascending order will produce less error than other ordering, especially descending order. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rand_arr = rand(500000);\n",
      "\n",
      "# use ascending order will give better result\n",
      "sorted_rand_arr = sort(rand_arr,rev=false)\n",
      "\n",
      "# simple loop \n",
      "@printf(\"simple sum:\\n\")\n",
      "@time @inbounds ret_1 = simple_sum(rand_arr, 1, length(rand_arr))\n",
      "@time @inbounds sorted_ret_1 = simple_sum(sorted_rand_arr, 1, length(rand_arr))\n",
      "\n",
      "\n",
      "@printf(\"\\npairwise sum:\\n\")\n",
      "# pairwise/ uses simple loop for small block\n",
      "@time @inbounds ret_2 = pair_sum(rand_arr, 1, length(rand_arr))\n",
      "@time @inbounds sorted_ret_2 = pair_sum(sorted_rand_arr, 1, length(rand_arr))\n",
      "\n",
      "# Julia's mapreduce\n",
      "@printf(\"\\nJulia's mapreduce:\\n\")\n",
      "@time @inbounds ret_3 = sum(rand_arr)\n",
      "@time @inbounds sorted_ret_3 = sum(sorted_rand_arr)\n",
      "\n",
      "# Kahan \n",
      "@printf(\"\\nKahan sum:\\n\")\n",
      "@time @inbounds ret_4 = kahan_sum(rand_arr)\n",
      "@time @inbounds sorted_ret_4 = kahan_sum(sorted_rand_arr)\n",
      "\n",
      "\n",
      "@printf(\"\\nunsorted simple   sum is %4.16lf.\\n\",ret_1);\n",
      "@printf(\"\\nsorted simple     sum is %4.16lf.\\n\",sorted_ret_1);\n",
      "@printf(\"\\nunsorted pairwise sum is %4.16lf.\\n\",ret_2);\n",
      "@printf(\"\\nsorted pairwise   sum is %4.16lf.\\n\",sorted_ret_2);\n",
      "@printf(\"\\nunsorted Julia's  sum is %4.16lf.\\n\",ret_3);\n",
      "@printf(\"\\nsorted Julia's    sum is %4.16lf.\\n\",sorted_ret_3);\n",
      "@printf(\"\\nunsorted Kahan    sum is %4.16lf.\\n\",ret_4);\n",
      "@printf(\"\\nsorted Kahan      sum is %4.16lf.\\n\",sorted_ret_4);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "simple sum:\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.005809853 seconds (106924 bytes allocated)\n",
        "elapsed time: 0.000699786 seconds (160 bytes allocated)\n",
        "\n",
        "pairwise sum:\n",
        "elapsed time: 0.00277834 seconds (59772 bytes allocated)\n",
        "elapsed time: 0.000565415 seconds (160 bytes allocated)\n",
        "\n",
        "Julia's mapreduce:\n",
        "elapsed time: 0.015840218 seconds (806376 bytes allocated)\n",
        "elapsed time: 0.000323421 seconds (144 bytes allocated)\n",
        "\n",
        "Kahan sum:\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00656717 seconds (181864 bytes allocated)\n",
        "elapsed time: 0.001592985 seconds (144 bytes allocated)\n",
        "\n",
        "unsorted simple   sum is 250069.8555895331955981.\n",
        "\n",
        "sorted simple     sum is 250069.8555895321769640.\n",
        "\n",
        "unsorted pairwise sum is 250069.8555895306926686.\n",
        "\n",
        "sorted pairwise   sum is 250069.8555895307217725.\n",
        "\n",
        "unsorted Julia's  sum is 250069.8555895299941767.\n",
        "\n",
        "sorted Julia's    sum is 250069.8555895304889418.\n",
        "\n",
        "unsorted Kahan    sum is 250069.8555895306926686.\n",
        "\n",
        "sorted Kahan      sum is 250069.8555895306926686.\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Comparison ###\n",
      "\n",
      "Here we can see ``Julia`` has faster summation algorithm. Let's look at how ``Julia`` deals with summation. The following is simplified version of ``Julia``'s summation(refer ``base/reduce.jl``) , the original code uses ``mapreduce`` to reduce temporary floating-point. The method used here is called [``Loop Unrolling``](http://en.wikipedia.org/wiki/Loop_unrolling). It is used for code optimization, trades the size of code with performance, by reducing instructions that control the loop and eliminating delay in communicating with memory.\n",
      "\n",
      "The following code unrolling its loop into four-way summation, and achieved ``2x`` applausible performance. However, even though the performance is pleasant, the error growth is still at level O(``eps`` n). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function julia_sum(a::AbstractArray, ifirst::Int, ilast::Int)\n",
      "    @inbounds if ifirst + 6 >= ilast # length(a) < 8\n",
      "        i = ifirst\n",
      "        s =  a[i] + a[i+1]\n",
      "        i = i+1\n",
      "        while i < ilast\n",
      "            s +=a[i+=1]\n",
      "        end\n",
      "        return s\n",
      "\n",
      "    else # length(a) >= 8, manual unrolling\n",
      "        @inbounds s1 = a[ifirst] +  a[ifirst + 4]\n",
      "        @inbounds s2 = a[ifirst + 1] + a[ifirst + 5]\n",
      "        @inbounds s3 = a[ifirst + 2] +  a[ifirst + 6]\n",
      "        @inbounds s4 = a[ifirst + 3] +  a[ifirst + 7]\n",
      "        i = ifirst + 8\n",
      "        il = ilast - 3\n",
      "        while i <= il\n",
      "          @inbounds  s1 +=  a[i]\n",
      "          @inbounds  s2 += a[i+1]\n",
      "          @inbounds  s3 += a[i+2]\n",
      "          @inbounds  s4 += a[i+3]\n",
      "            i += 4\n",
      "        end\n",
      "        while i <= ilast\n",
      "          @inbounds  s1 += a[i]\n",
      "            i += 1\n",
      "        end\n",
      "        return s1 + s2 + s3 + s4\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "julia_sum (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rand_arr = rand(500000);\n",
      "\n",
      "# use ascending order will give better result\n",
      "sorted_rand_arr = sort(rand_arr,rev=false)\n",
      "\n",
      "# Julia's mapreduce\n",
      "@printf(\"\\nJulia's mapreduce:\\n\")\n",
      "@time @inbounds ret = julia_sum(rand_arr,1,500000)\n",
      "@time @inbounds sorted_ret = julia_sum(sorted_rand_arr, 1, 500000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Julia's mapreduce:\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000383906 seconds (96 bytes allocated)\n",
        "elapsed time: 0.000350468 seconds (96 bytes allocated)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although it seems compensated method takes much longer time than other methods, we still have to use these methods for high accuracy computing, like long term integration, simple loop will explode our accuracy at some time, but Kahan will never ruin our result too much. Following example shows the integration of function ``sin(x)`` over ``[0, Pi]``, using simple loop and Kahan both, we can see the error of simple loop at the last case begins to raise, which would generate a U-shape plot, while Kahan makes the error continue to decrease."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Caution: this may takes time\n",
      "f(x) = sin(x)\n",
      "\n",
      "@time for i = 1:8\n",
      "    SIZE = 10^i\n",
      "    nodes = zeros(SIZE)\n",
      "    \n",
      "    # most time spent on evaluating function as assignment\n",
      "    for j = 1:SIZE\n",
      "        @inbounds nodes[j] = sin(j*pi/SIZE)*pi/SIZE\n",
      "    end\n",
      "\n",
      "    \n",
      "    ret_1 = simple_sum(nodes,1,SIZE)\n",
      "    ret_2 = kahan_sum(nodes)\n",
      "    # unsorted julia summation\n",
      "    ret_3 = julia_sum(nodes,1, SIZE)\n",
      "    # sorted julia summation\n",
      "    sort!(nodes, rev=false)\n",
      "    ret_4 = julia_sum(nodes,1,SIZE)\n",
      "    @printf(\"%8d\\t%4.16lf \\t%4.16lf\\t%4.16lf\\t%4.16lf\\n\", \n",
      "        i, log(abs(ret_1 - 2.0)), log(abs(ret_2 - 2.0)), log(abs(ret_3 - 2.0)),log(abs(ret_4 - 2.0)))\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      1\t-4.1058224322423200 \t-4.1058224322423333\t-4.1058224322423200\t-4.1058224322423333\n",
        "       2\t-8.7126236199139360 \t-8.7126236199139360\t-8.7126236199139360\t-8.7126236199125859\n",
        "       3\t-13.3178100916878037 \t-13.3178100910128698\t-13.3178100907428956\t-13.3178100907428956\n",
        "       4\t-17.9229807587693628 \t-17.9229804348006709\t-17.9229805022941413\t-17.9229805292915287\n",
        "       5\t-22.5280972348821109 \t-22.5281512282301435\t-22.5281431290420855\t-22.5281228813589287\n",
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      6\t-27.1296995302229007 \t-27.1333376127911414\t-27.1321234473805966\t-27.1379378103230664\n",
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      7\t-30.4341815939321947 \t-31.7395882959129878\t-31.3251545178220603\t-30.4452314301187812\n",
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      8\t-27.8666995208913768 \t-36.0436533891171536\t-29.3946688390923789\t-30.5142243016057328\n",
        "elapsed time: 16.852989512 seconds (888997872 bytes allocated, 0.37% gc time)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see the effect of Kahan method from above, when simple loop summation accumulates the error, ``kahan_sum`` still can make the curve goes down. For the comparison of sorted and unsorted ``Julia`` summation, the error curve can be flatten by sorting the data before operation on it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Numbers ##\n",
      "\n",
      "There is no real random numbers in ``Julia``, the pseudorandom generator uses [``Double precision SIMD-oriented Fast Mersenne Twister (dSFMT)``](http://www.math.sci.hiroshima-u.ac.jp/~%20m-mat/MT/SFMT/index.html)(refer the [``paper``](http://www.math.sci.hiroshima-u.ac.jp/~%20m-mat/MT/ARTICLES/sfmt.pdf) ) which is described in ``base/dFSMT.jl``, for those C++ users, probably they are more familiar with ``mt19937`` and ``mt19937_64``.\n",
      "\n",
      "\n",
      "``Julia`` also provides a ``randn`` function, which uses [``Ziggurat algorithm``](http://en.wikipedia.org/wiki/Ziggurat_algorithm), it is a rejection sampling algorithm. For more detailed information about ``RNG``, please refer Chapter ``Probability``."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}